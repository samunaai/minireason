Starting data generation...
Starting parallel data generation for 100,000 samples on 64 workers (256 tasks)...
Generating Sample Batches:   0%|          | 0/256 [00:00<?, ?it/s]Generating Sample Batches:   0%|          | 1/256 [18:09<77:11:56, 1089.87s/it]Generating Sample Batches:   1%|          | 3/256 [18:24<20:14:36, 288.05s/it] Generating Sample Batches:   2%|▏         | 5/256 [18:52<10:15:31, 147.14s/it]Generating Sample Batches:   3%|▎         | 7/256 [19:17<6:14:02, 90.13s/it]  Generating Sample Batches:   4%|▎         | 9/256 [19:23<3:55:42, 57.26s/it]Generating Sample Batches:   4%|▍         | 11/256 [19:26<2:33:47, 37.66s/it]Generating Sample Batches:   5%|▌         | 13/256 [19:33<1:46:23, 26.27s/it]Generating Sample Batches:   6%|▌         | 15/256 [19:44<1:18:51, 19.63s/it]Generating Sample Batches:   7%|▋         | 17/256 [19:47<55:23, 13.91s/it]  Generating Sample Batches:   7%|▋         | 19/256 [19:48<38:27,  9.73s/it]Generating Sample Batches:   9%|▉         | 23/256 [19:52<21:50,  5.62s/it]Generating Sample Batches:  10%|▉         | 25/256 [19:56<18:01,  4.68s/it]Generating Sample Batches:  11%|█         | 27/256 [19:57<14:06,  3.70s/it]Generating Sample Batches:  11%|█▏        | 29/256 [20:00<11:36,  3.07s/it]Generating Sample Batches:  12%|█▏        | 31/256 [20:04<10:12,  2.72s/it]Generating Sample Batches:  13%|█▎        | 33/256 [20:06<08:11,  2.20s/it]Generating Sample Batches:  14%|█▎        | 35/256 [20:06<05:51,  1.59s/it]Generating Sample Batches:  14%|█▍        | 37/256 [20:07<04:46,  1.31s/it]Generating Sample Batches:  15%|█▌        | 39/256 [20:14<06:41,  1.85s/it]Generating Sample Batches:  16%|█▌        | 41/256 [20:25<10:31,  2.94s/it]Generating Sample Batches:  17%|█▋        | 43/256 [20:27<08:47,  2.48s/it]Generating Sample Batches:  18%|█▊        | 45/256 [20:30<07:18,  2.08s/it]Generating Sample Batches:  18%|█▊        | 47/256 [20:32<06:31,  1.87s/it]Generating Sample Batches:  19%|█▉        | 49/256 [20:41<09:11,  2.66s/it]Generating Sample Batches:  20%|█▉        | 51/256 [20:44<07:27,  2.18s/it]Generating Sample Batches:  21%|██        | 53/256 [20:47<06:57,  2.06s/it]Generating Sample Batches:  21%|██▏       | 55/256 [20:49<05:53,  1.76s/it]Generating Sample Batches:  23%|██▎       | 59/256 [20:58<06:36,  2.01s/it]Generating Sample Batches:  24%|██▍       | 61/256 [21:05<07:36,  2.34s/it]Generating Sample Batches:  25%|██▍       | 63/256 [21:13<08:41,  2.70s/it]Generating Sample Batches:  25%|██▌       | 65/256 [21:22<10:14,  3.22s/it]Generating Sample Batches:  26%|██▌       | 67/256 [21:34<12:41,  4.03s/it]Generating Sample Batches:  27%|██▋       | 69/256 [21:36<09:53,  3.18s/it]Generating Sample Batches:  28%|██▊       | 71/256 [21:39<08:03,  2.61s/it]Generating Sample Batches:  29%|██▊       | 73/256 [21:43<07:41,  2.52s/it]Generating Sample Batches:  29%|██▉       | 75/256 [21:43<05:28,  1.81s/it]Generating Sample Batches:  30%|███       | 77/256 [21:46<05:04,  1.70s/it]Generating Sample Batches:  31%|███       | 79/256 [21:48<04:28,  1.52s/it]Generating Sample Batches:  32%|███▏      | 81/256 [21:50<03:48,  1.31s/it]Generating Sample Batches:  32%|███▏      | 83/256 [22:08<10:17,  3.57s/it]Generating Sample Batches:  33%|███▎      | 85/256 [22:11<08:28,  2.97s/it]Generating Sample Batches:  34%|███▍      | 87/256 [22:13<06:36,  2.35s/it]Generating Sample Batches:  35%|███▍      | 89/256 [22:17<06:12,  2.23s/it]Generating Sample Batches:  36%|███▌      | 91/256 [22:19<05:15,  1.91s/it]Generating Sample Batches:  36%|███▋      | 93/256 [22:20<04:02,  1.49s/it]Generating Sample Batches:  37%|███▋      | 95/256 [22:22<03:36,  1.35s/it]Generating Sample Batches:  38%|███▊      | 97/256 [22:23<02:42,  1.02s/it]Generating Sample Batches:  39%|███▊      | 99/256 [22:26<03:16,  1.25s/it]Generating Sample Batches:  39%|███▉      | 101/256 [22:30<03:39,  1.42s/it]Generating Sample Batches:  40%|████      | 103/256 [22:37<05:21,  2.10s/it]Generating Sample Batches:  41%|████      | 105/256 [22:40<04:45,  1.89s/it]Generating Sample Batches:  42%|████▏     | 107/256 [22:48<06:10,  2.49s/it]Generating Sample Batches:  43%|████▎     | 109/256 [22:50<05:01,  2.05s/it]Generating Sample Batches:  43%|████▎     | 111/256 [22:53<04:46,  1.97s/it]Generating Sample Batches:  44%|████▍     | 113/256 [22:59<05:16,  2.21s/it]Generating Sample Batches:  45%|████▍     | 115/256 [23:04<05:31,  2.35s/it]Generating Sample Batches:  46%|████▌     | 117/256 [23:20<09:19,  4.02s/it]Generating Sample Batches:  46%|████▋     | 119/256 [23:44<14:43,  6.45s/it]Generating Sample Batches:  47%|████▋     | 121/256 [23:58<14:43,  6.54s/it]Generating Sample Batches:  48%|████▊     | 123/256 [24:01<11:08,  5.02s/it]Generating Sample Batches:  49%|████▉     | 125/256 [24:05<09:05,  4.17s/it]Generating Sample Batches:  50%|████▉     | 127/256 [24:07<06:44,  3.14s/it]Generating Sample Batches:  50%|█████     | 129/256 [35:57<3:50:22, 108.84s/it]Generating Sample Batches:  51%|█████     | 131/256 [37:44<3:12:08, 92.23s/it] Generating Sample Batches:  52%|█████▏    | 133/256 [37:55<2:15:39, 66.17s/it]Generating Sample Batches:  53%|█████▎    | 135/256 [38:06<1:36:45, 47.98s/it]Generating Sample Batches:  54%|█████▎    | 137/256 [38:33<1:14:41, 37.66s/it]Generating Sample Batches:  54%|█████▍    | 139/256 [38:49<56:06, 28.77s/it]  Generating Sample Batches:  55%|█████▌    | 141/256 [38:50<38:42, 20.20s/it]Generating Sample Batches:  56%|█████▌    | 143/256 [39:18<34:27, 18.30s/it]Generating Sample Batches:  57%|█████▋    | 145/256 [39:20<24:26, 13.21s/it]Generating Sample Batches:  57%|█████▋    | 147/256 [39:25<18:12, 10.02s/it]Generating Sample Batches:  58%|█████▊    | 149/256 [39:40<16:29,  9.25s/it]Generating Sample Batches:  59%|█████▉    | 151/256 [39:49<13:43,  7.85s/it]Generating Sample Batches:  60%|█████▉    | 153/256 [40:10<14:44,  8.59s/it]Generating Sample Batches:  61%|██████    | 155/256 [40:15<11:21,  6.75s/it]Generating Sample Batches:  61%|██████▏   | 157/256 [40:18<08:38,  5.24s/it]Generating Sample Batches:  62%|██████▏   | 159/256 [40:30<08:47,  5.44s/it]Generating Sample Batches:  63%|██████▎   | 161/256 [40:31<06:11,  3.91s/it]Generating Sample Batches:  64%|██████▎   | 163/256 [40:32<04:30,  2.91s/it]Generating Sample Batches:  64%|██████▍   | 165/256 [40:34<03:35,  2.37s/it]Generating Sample Batches:  65%|██████▌   | 167/256 [40:35<02:30,  1.69s/it]Generating Sample Batches:  66%|██████▌   | 169/256 [40:35<01:50,  1.27s/it]Generating Sample Batches:  67%|██████▋   | 171/256 [40:41<02:30,  1.77s/it]Generating Sample Batches:  68%|██████▊   | 173/256 [40:43<02:10,  1.58s/it]Generating Sample Batches:  68%|██████▊   | 175/256 [40:53<03:23,  2.51s/it]Generating Sample Batches:  69%|██████▉   | 177/256 [40:58<03:22,  2.57s/it]Generating Sample Batches:  70%|██████▉   | 179/256 [40:59<02:26,  1.91s/it]Generating Sample Batches:  71%|███████   | 181/256 [41:00<01:55,  1.55s/it]Generating Sample Batches:  71%|███████▏  | 183/256 [41:04<01:57,  1.61s/it]Generating Sample Batches:  72%|███████▏  | 185/256 [41:05<01:33,  1.32s/it]Generating Sample Batches:  73%|███████▎  | 187/256 [41:05<01:08,  1.01it/s]Generating Sample Batches:  74%|███████▍  | 189/256 [41:05<00:47,  1.41it/s]Generating Sample Batches:  75%|███████▍  | 191/256 [41:08<01:00,  1.07it/s]Generating Sample Batches:  75%|███████▌  | 193/256 [41:20<02:33,  2.44s/it]Generating Sample Batches:  76%|███████▌  | 195/256 [41:21<01:47,  1.76s/it]Generating Sample Batches:  77%|███████▋  | 197/256 [41:25<01:47,  1.81s/it]Generating Sample Batches:  78%|███████▊  | 199/256 [41:27<01:33,  1.64s/it]Generating Sample Batches:  79%|███████▊  | 201/256 [41:28<01:14,  1.36s/it]Generating Sample Batches:  79%|███████▉  | 203/256 [41:33<01:29,  1.70s/it]Generating Sample Batches:  80%|████████  | 205/256 [41:33<01:01,  1.21s/it]Generating Sample Batches:  81%|████████  | 207/256 [41:34<00:43,  1.12it/s]Generating Sample Batches:  82%|████████▏ | 209/256 [41:38<01:00,  1.29s/it]Generating Sample Batches:  82%|████████▏ | 211/256 [41:40<00:53,  1.18s/it]Generating Sample Batches:  83%|████████▎ | 213/256 [41:42<00:50,  1.17s/it]Generating Sample Batches:  84%|████████▍ | 215/256 [41:44<00:43,  1.06s/it]Generating Sample Batches:  86%|████████▌ | 219/256 [41:44<00:21,  1.69it/s]Generating Sample Batches:  86%|████████▋ | 221/256 [41:45<00:21,  1.66it/s]Generating Sample Batches:  87%|████████▋ | 223/256 [41:47<00:21,  1.53it/s]Generating Sample Batches:  88%|████████▊ | 225/256 [41:48<00:17,  1.79it/s]Generating Sample Batches:  89%|████████▊ | 227/256 [41:57<00:49,  1.70s/it]Generating Sample Batches:  89%|████████▉ | 229/256 [41:57<00:34,  1.27s/it]Generating Sample Batches:  90%|█████████ | 231/256 [41:58<00:24,  1.04it/s]Generating Sample Batches:  91%|█████████ | 233/256 [41:58<00:16,  1.36it/s]Generating Sample Batches:  92%|█████████▏| 235/256 [41:58<00:11,  1.80it/s]Generating Sample Batches:  93%|█████████▎| 237/256 [41:59<00:07,  2.42it/s]Generating Sample Batches:  93%|█████████▎| 239/256 [41:59<00:05,  3.03it/s]Generating Sample Batches:  94%|█████████▍| 241/256 [42:01<00:07,  1.99it/s]Generating Sample Batches:  95%|█████████▍| 243/256 [42:01<00:05,  2.56it/s]Generating Sample Batches:  96%|█████████▌| 245/256 [42:02<00:04,  2.47it/s]Generating Sample Batches:  96%|█████████▋| 247/256 [42:02<00:03,  2.80it/s]Generating Sample Batches:  97%|█████████▋| 249/256 [42:03<00:02,  2.43it/s]Generating Sample Batches:  98%|█████████▊| 251/256 [42:04<00:01,  2.53it/s]Generating Sample Batches: 100%|█████████▉| 255/256 [42:09<00:00,  1.20it/s]Generating Sample Batches: 100%|██████████| 256/256 [42:09<00:00,  9.88s/it]
Generated 100,249 solutions from 38,521 problem draws (~2.60 solutions/draw, 92.4% draws with ≥1 solution).
  Total Rejects (solver): 2,889.
Saving generated data to: countdown_data_100000_samples_6_K3_digit_tokenized.pt
[RANK 0] Loading data from countdown_data_100000_samples_6_K3_digit_tokenized.pt
/home/kentaro.inui/anaconda3/envs/interpretability/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/home/kentaro.inui/sam/minireason/run_countdown_pretraining.py:806: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=False)

==============================================================
                      Run Configuration                       
==============================================================
                  --- System & Hardware ---                   
PyTorch Version:             2.7.1+cu126
Available GPUs:              4
DDP Enabled:                 No

                     --- Data & Vocab ---                     
Total Dataset Size:          100,000 samples
Train / Validation Split:    90,000 / 10,000
Problem Type:                6-number Countdown
Vocabulary Size:             26 tokens

                  --- Model Architecture ---                  
d_model / n_heads / n_layers: 128 / 4 / 4
Total Parameters:            827,904 
Max Sequence Length:         244 (prompt=26, solution=217)
Seq Len Cap (env):           2048

               --- Training Hyperparameters ---               
Epochs (Max):                1000
Early Stopping Patience:     20
Batch Size:                  32
Learning Rate:               0.0003
Weight Decay:                0.01
Gradient Checkpointing:      Disabled
Random Seed:                 42
Max Solutions per Problem:   3
==============================================================

Starting training on rank 0...
/home/kentaro.inui/sam/minireason/run_countdown_pretraining.py:516: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=use_amp), \
Epoch 0001 | Train loss 1.3267 | Val loss 0.4231
  -> New best val loss. Checkpoint saved.
Epoch 0002 | Train loss 0.2895 | Val loss 0.2139
  -> New best val loss. Checkpoint saved.
Epoch 0003 | Train loss 0.1780 | Val loss 0.1542
  -> New best val loss. Checkpoint saved.
Epoch 0004 | Train loss 0.1331 | Val loss 0.1221
  -> New best val loss. Checkpoint saved.
Epoch 0005 | Train loss 0.1107 | Val loss 0.1054
  -> New best val loss. Checkpoint saved.
Epoch 0006 | Train loss 0.0986 | Val loss 0.0989
  -> New best val loss. Checkpoint saved.
Epoch 0007 | Train loss 0.0913 | Val loss 0.0917
  -> New best val loss. Checkpoint saved.
Epoch 0008 | Train loss 0.0863 | Val loss 0.0858
  -> New best val loss. Checkpoint saved.
Epoch 0009 | Train loss 0.0829 | Val loss 0.0829
  -> New best val loss. Checkpoint saved.
Epoch 0010 | Train loss 0.0802 | Val loss 0.0836
Epoch 0011 | Train loss 0.0774 | Val loss 0.0773
  -> New best val loss. Checkpoint saved.
Epoch 0012 | Train loss 0.0752 | Val loss 0.0766
  -> New best val loss. Checkpoint saved.
Epoch 0013 | Train loss 0.0728 | Val loss 0.0741
  -> New best val loss. Checkpoint saved.
Epoch 0014 | Train loss 0.0710 | Val loss 0.0722
  -> New best val loss. Checkpoint saved.
Epoch 0015 | Train loss 0.0697 | Val loss 0.0728
Epoch 0016 | Train loss 0.0686 | Val loss 0.0715
  -> New best val loss. Checkpoint saved.
Epoch 0017 | Train loss 0.0675 | Val loss 0.0715
  -> New best val loss. Checkpoint saved.
Epoch 0018 | Train loss 0.0668 | Val loss 0.0692
  -> New best val loss. Checkpoint saved.
Epoch 0019 | Train loss 0.0660 | Val loss 0.0694
Epoch 0020 | Train loss 0.0654 | Val loss 0.0681
  -> New best val loss. Checkpoint saved.
Epoch 0021 | Train loss 0.0648 | Val loss 0.0680
  -> New best val loss. Checkpoint saved.
Epoch 0022 | Train loss 0.0642 | Val loss 0.0678
  -> New best val loss. Checkpoint saved.
Epoch 0023 | Train loss 0.0636 | Val loss 0.0666
  -> New best val loss. Checkpoint saved.
Epoch 0024 | Train loss 0.0632 | Val loss 0.0665
  -> New best val loss. Checkpoint saved.
Epoch 0025 | Train loss 0.0627 | Val loss 0.0671
Epoch 0026 | Train loss 0.0622 | Val loss 0.0667
Epoch 0027 | Train loss 0.0618 | Val loss 0.0659
  -> New best val loss. Checkpoint saved.
Epoch 0028 | Train loss 0.0612 | Val loss 0.0665
Epoch 0029 | Train loss 0.0609 | Val loss 0.0655
  -> New best val loss. Checkpoint saved.
Epoch 0030 | Train loss 0.0604 | Val loss 0.0662
Epoch 0031 | Train loss 0.0599 | Val loss 0.0648
  -> New best val loss. Checkpoint saved.
Epoch 0032 | Train loss 0.0595 | Val loss 0.0652
Epoch 0033 | Train loss 0.0591 | Val loss 0.0652
Epoch 0034 | Train loss 0.0586 | Val loss 0.0644
  -> New best val loss. Checkpoint saved.
Epoch 0035 | Train loss 0.0582 | Val loss 0.0647
Epoch 0036 | Train loss 0.0577 | Val loss 0.0655
Epoch 0037 | Train loss 0.0573 | Val loss 0.0641
  -> New best val loss. Checkpoint saved.
Epoch 0038 | Train loss 0.0568 | Val loss 0.0651
Epoch 0039 | Train loss 0.0564 | Val loss 0.0645
Epoch 0040 | Train loss 0.0558 | Val loss 0.0653
Epoch 0041 | Train loss 0.0553 | Val loss 0.0652
Epoch 0042 | Train loss 0.0548 | Val loss 0.0648
Epoch 0043 | Train loss 0.0543 | Val loss 0.0649
Epoch 0044 | Train loss 0.0537 | Val loss 0.0646
Epoch 0045 | Train loss 0.0532 | Val loss 0.0643
Epoch 0046 | Train loss 0.0527 | Val loss 0.0645
Epoch 0047 | Train loss 0.0521 | Val loss 0.0656
Epoch 0048 | Train loss 0.0515 | Val loss 0.0652
Epoch 0049 | Train loss 0.0509 | Val loss 0.0649
Epoch 0050 | Train loss 0.0503 | Val loss 0.0652
Epoch 0051 | Train loss 0.0499 | Val loss 0.0657
Epoch 0052 | Train loss 0.0492 | Val loss 0.0653
Epoch 0053 | Train loss 0.0487 | Val loss 0.0653
Epoch 0054 | Train loss 0.0481 | Val loss 0.0656
Epoch 0055 | Train loss 0.0476 | Val loss 0.0660
Epoch 0056 | Train loss 0.0470 | Val loss 0.0656
Epoch 0057 | Train loss 0.0465 | Val loss 0.0659
Stopping early.

Training plot saved to countdown_training_plot.png

Loading best model for final evaluation...
/home/kentaro.inui/sam/minireason/run_countdown_pretraining.py:627: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(dtype=torch.bfloat16, enabled=use_amp):

--- Final Evaluation Metrics ---
  Program Exact Match:         0.00%
  Verified Answer Accuracy:    25.78%
  Op Validity Rate:            54.17%
  Op State-Consistency Rate:   0.00%
----------------------------------
on 128 validation samples.

--- Inference Examples ---

--- Example #1 ---
Problem:      IN: [ 8, 4, 3, 2, 100, 75 ] TGT: 644
True Sol:     [ 2, 3, 4, 8, 75, 100 ] -> 75 + 100 = 175 -> [ 2, 3, 4, 8, 175 ] ; [ 2, 3, 4, 8, 175 ] -> 2 * 3 = 6 -> [ 4, 6, 8, 175 ] ; [ 4, 6, 8, 175 ] -> 6 + 8 = 14 -> [ 4, 14, 175 ] ; [ 4, 14, 175 ] -> 175 - 14 = 161 -> [ 4, 161 ] ; [ 4, 161 ] -> 4 * 161 = 644 -> [ 644 ] ; ANSWER
Generated Sol: [ 2, 3, 4, 8, 75, 100 ] -> 4 + 100 = 1041074 -> [ 2, 3, 8, 75, 1074 ] ; [ 2, 3, 8, 75, 1074 ] -> 8 + 75 = 83 -> [ 2, 3, 83, 1074 ] ; [ 2, 3, 83, 1074 ] -> 2 * 83 = 166 -> [ 3, 166, 1074 ] ; [ 3, 166, 1074 ] -> 166 + 1074 = 1230 -> [ 3, 1230 ] ; [ 3, 1230 ] -> 1230 / 3 = 644 -> [ 644 ] ; ANSWER

--- Example #2 ---
Problem:      IN: [ 3, 75, 50, 2, 10, 100 ] TGT: 702
True Sol:     [ 2, 3, 10, 50, 75, 100 ] -> 2 + 100 = 102 -> [ 3, 10, 50, 75, 102 ] ; [ 3, 10, 50, 75, 102 ] -> 10 * 75 = 750 -> [ 3, 50, 102, 750 ] ; [ 3, 50, 102, 750 ] -> 3 * 50 = 150 -> [ 102, 150, 750 ] ; [ 102, 150, 750 ] -> 150 - 102 = 48 -> [ 48, 750 ] ; [ 48, 750 ] -> 750 - 48 = 702 -> [ 702 ] ; ANSWER
Generated Sol: [ 2, 3, 10, 50, 75, 100 ] -> 10 * 50 = 5005050 -> [ 2, 3, 75, 100, 5000 ] ; [ 2, 3, 75, 100, 5000 ] -> 5000 - 2 = 4998 -> [ 3, 75, 100, 4998 ] ; [ 3, 75, 100, 4998 ] -> 4998 / 3 = 1636 -> [ 75, 100, 1636 ] ; [ 75, 100, 1636 ] -> 1636 - 100 = 1536 -> [ 75, 1536 ] ; [ 75, 1536 ] -> 1536 - 75 = 702 -> [ 702 ] ; ANSWER

--- Example #3 ---
Problem:      IN: [ 50, 75, 2, 100, 10, 6 ] TGT: 271
True Sol:     [ 2, 6, 10, 50, 75, 100 ] -> 50 * 75 = 3750 -> [ 2, 6, 10, 100, 3750 ] ; [ 2, 6, 10, 100, 3750 ] -> 6 + 100 = 106 -> [ 2, 10, 106, 3750 ] ; [ 2, 10, 106, 3750 ] -> 3750 / 10 = 375 -> [ 2, 106, 375 ] ; [ 2, 106, 375 ] -> 375 - 106 = 269 -> [ 2, 269 ] ; [ 2, 269 ] -> 2 + 269 = 271 -> [ 271 ] ; ANSWER
Generated Sol: [ 2, 6, 10, 50, 75, 100 ] -> 50 + 100 = 1501550 -> [ 2, 6, 10, 75, 1550 ] ; [ 2, 6, 10, 75, 1550 ] -> 1550 / 75 = 23 -> [ 2, 2, 10, 75 ] ; [ 2, 2, 10, 75 ] -> 10 - 2 = 8 -> [ 2, 8, 75 ] ; [ 2, 8, 75 ] -> 8 * 2 = 16 -> [ 16, 75 ] ; [ 16, 75 ] -> 16 + 75 = 81 -> [ 81 ] ; ANSWER

--- Example #4 ---
Problem:      IN: [ 2, 100, 4, 5, 9, 10 ] TGT: 123
True Sol:     [ 2, 4, 5, 9, 10, 100 ] -> 4 + 10 = 14 -> [ 2, 5, 9, 14, 100 ] ; [ 2, 5, 9, 14, 100 ] -> 100 - 2 = 98 -> [ 5, 9, 14, 98 ] ; [ 5, 9, 14, 98 ] -> 14 - 9 = 5 -> [ 5, 5, 98 ] ; [ 5, 5, 98 ] -> 5 * 5 = 25 -> [ 25, 98 ] ; [ 25, 98 ] -> 25 + 98 = 123 -> [ 123 ] ; ANSWER
Generated Sol: [ 2, 4, 5, 9, 10, 100 ] -> 2 + 10 = 12124 -> [ 4, 5, 9, 10, 124 ] ; [ 4, 5, 9, 10, 124 ] -> 4 + 10 = 14 -> [ 5, 9, 14, 124 ] ; [ 5, 9, 14, 124 ] -> 9 - 5 = 4 -> [ 4, 14, 124 ] ; [ 4, 14, 124 ] -> 4 * 14 = 56 -> [ 56, 124 ] ; [ 56, 124 ] -> 56 + 124 = 123 -> [ 123 ] ; ANSWER

--- Example #5 ---
Problem:      IN: [ 7, 3, 5, 25, 100, 50 ] TGT: 392
True Sol:     [ 3, 5, 7, 25, 50, 100 ] -> 5 + 7 = 12 -> [ 3, 12, 25, 50, 100 ] ; [ 3, 12, 25, 50, 100 ] -> 50 / 25 = 2 -> [ 2, 3, 12, 100 ] ; [ 2, 3, 12, 100 ] -> 100 - 2 = 98 -> [ 3, 12, 98 ] ; [ 3, 12, 98 ] -> 12 * 98 = 1176 -> [ 3, 1176 ] ; [ 3, 1176 ] -> 1176 / 3 = 392 -> [ 392 ] ; ANSWER
Generated Sol: [ 3, 5, 7, 25, 50, 100 ] -> 5 + 7 = 1274 -> [ 3, 7, 25, 50, 100 ] ; [ 3, 7, 25, 50, 100 ] -> 3 + 100 = 103 -> [ 7, 25, 103, 50 ] ; [ 7, 25, 103, 50 ] -> 103 - 7 = 96 -> [ 25, 96, 50 ] ; [ 25, 96, 50 ] -> 96 * 50 = 4900 -> [ 25, 4900 ] ; [ 25, 4900 ] -> 4900 / 25 = 192 -> [ 192 ] ; ANSWER

Total runtime: 77.03 minutes (4621.8 seconds)
